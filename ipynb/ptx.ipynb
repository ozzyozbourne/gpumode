{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0S5pwY-SrgL",
        "outputId": "3a8a8696-1e33-4a9c-8941-52c5aca0f313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  4 11:31:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "name, compute_cap\n",
            "Tesla T4, 7.5\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!nvidia-smi --query-gpu=name,compute_cap --format=csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(const float *A, const float *B, float *C, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        C[idx] = A[idx] + B[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1024;\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy result back\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Verify result\n",
        "    bool success = true;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        if (fabs(h_C[i] - (h_A[i] + h_B[i])) > 1e-5) {\n",
        "            success = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    printf(\"Vector addition %s!\\n\", success ? \"PASSED\" : \"FAILED\");\n",
        "    printf(\"Result: C[0]=%.1f, C[511]=%.1f, C[1023]=%.1f\\n\",\n",
        "           h_C[0], h_C[511], h_C[1023]);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YrKGiA8TSwc",
        "outputId": "a6d3fc53-23ee-4b3d-eb0d-ef83d097a538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -ptx vector_add.cu -o vector_add.ptx\n",
        "!cat vector_add.ptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClpdUpl7TrtR",
        "outputId": "8d0c9c3f-e7e3-4efb-83d1-32693b13f204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//\n",
            "// Generated by NVIDIA NVVM Compiler\n",
            "//\n",
            "// Compiler Build ID: CL-34385749\n",
            "// Cuda compilation tools, release 12.5, V12.5.82\n",
            "// Based on NVVM 7.0.1\n",
            "//\n",
            "\n",
            ".version 8.5\n",
            ".target sm_52\n",
            ".address_size 64\n",
            "\n",
            "\t// .globl\t_Z9vectorAddPKfS0_Pfi\n",
            "\n",
            ".visible .entry _Z9vectorAddPKfS0_Pfi(\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_0,\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_1,\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_2,\n",
            "\t.param .u32 _Z9vectorAddPKfS0_Pfi_param_3\n",
            ")\n",
            "{\n",
            "\t.reg .pred \t%p<2>;\n",
            "\t.reg .f32 \t%f<4>;\n",
            "\t.reg .b32 \t%r<6>;\n",
            "\t.reg .b64 \t%rd<11>;\n",
            "\n",
            "\n",
            "\tld.param.u64 \t%rd1, [_Z9vectorAddPKfS0_Pfi_param_0];\n",
            "\tld.param.u64 \t%rd2, [_Z9vectorAddPKfS0_Pfi_param_1];\n",
            "\tld.param.u64 \t%rd3, [_Z9vectorAddPKfS0_Pfi_param_2];\n",
            "\tld.param.u32 \t%r2, [_Z9vectorAddPKfS0_Pfi_param_3];\n",
            "\tmov.u32 \t%r3, %ctaid.x;\n",
            "\tmov.u32 \t%r4, %ntid.x;\n",
            "\tmov.u32 \t%r5, %tid.x;\n",
            "\tmad.lo.s32 \t%r1, %r3, %r4, %r5;\n",
            "\tsetp.ge.s32 \t%p1, %r1, %r2;\n",
            "\t@%p1 bra \t$L__BB0_2;\n",
            "\n",
            "\tcvta.to.global.u64 \t%rd4, %rd1;\n",
            "\tmul.wide.s32 \t%rd5, %r1, 4;\n",
            "\tadd.s64 \t%rd6, %rd4, %rd5;\n",
            "\tcvta.to.global.u64 \t%rd7, %rd2;\n",
            "\tadd.s64 \t%rd8, %rd7, %rd5;\n",
            "\tld.global.f32 \t%f1, [%rd8];\n",
            "\tld.global.f32 \t%f2, [%rd6];\n",
            "\tadd.f32 \t%f3, %f2, %f1;\n",
            "\tcvta.to.global.u64 \t%rd9, %rd3;\n",
            "\tadd.s64 \t%rd10, %rd9, %rd5;\n",
            "\tst.global.f32 \t[%rd10], %f3;\n",
            "\n",
            "$L__BB0_2:\n",
            "\tret;\n",
            "\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/.version 8.5/.version 8.4/' vector_add.ptx\n",
        "!cat vector_add.ptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zpXWwnFZ3Yv",
        "outputId": "8bdf28b2-b3a2-43c3-a298-789494f36679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//\n",
            "// Generated by NVIDIA NVVM Compiler\n",
            "//\n",
            "// Compiler Build ID: CL-34385749\n",
            "// Cuda compilation tools, release 12.5, V12.5.82\n",
            "// Based on NVVM 7.0.1\n",
            "//\n",
            "\n",
            ".version 8.4\n",
            ".target sm_52\n",
            ".address_size 64\n",
            "\n",
            "\t// .globl\t_Z9vectorAddPKfS0_Pfi\n",
            "\n",
            ".visible .entry _Z9vectorAddPKfS0_Pfi(\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_0,\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_1,\n",
            "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_2,\n",
            "\t.param .u32 _Z9vectorAddPKfS0_Pfi_param_3\n",
            ")\n",
            "{\n",
            "\t.reg .pred \t%p<2>;\n",
            "\t.reg .f32 \t%f<4>;\n",
            "\t.reg .b32 \t%r<6>;\n",
            "\t.reg .b64 \t%rd<11>;\n",
            "\n",
            "\n",
            "\tld.param.u64 \t%rd1, [_Z9vectorAddPKfS0_Pfi_param_0];\n",
            "\tld.param.u64 \t%rd2, [_Z9vectorAddPKfS0_Pfi_param_1];\n",
            "\tld.param.u64 \t%rd3, [_Z9vectorAddPKfS0_Pfi_param_2];\n",
            "\tld.param.u32 \t%r2, [_Z9vectorAddPKfS0_Pfi_param_3];\n",
            "\tmov.u32 \t%r3, %ctaid.x;\n",
            "\tmov.u32 \t%r4, %ntid.x;\n",
            "\tmov.u32 \t%r5, %tid.x;\n",
            "\tmad.lo.s32 \t%r1, %r3, %r4, %r5;\n",
            "\tsetp.ge.s32 \t%p1, %r1, %r2;\n",
            "\t@%p1 bra \t$L__BB0_2;\n",
            "\n",
            "\tcvta.to.global.u64 \t%rd4, %rd1;\n",
            "\tmul.wide.s32 \t%rd5, %r1, 4;\n",
            "\tadd.s64 \t%rd6, %rd4, %rd5;\n",
            "\tcvta.to.global.u64 \t%rd7, %rd2;\n",
            "\tadd.s64 \t%rd8, %rd7, %rd5;\n",
            "\tld.global.f32 \t%f1, [%rd8];\n",
            "\tld.global.f32 \t%f2, [%rd6];\n",
            "\tadd.f32 \t%f3, %f2, %f1;\n",
            "\tcvta.to.global.u64 \t%rd9, %rd3;\n",
            "\tadd.s64 \t%rd10, %rd9, %rd5;\n",
            "\tst.global.f32 \t[%rd10], %f3;\n",
            "\n",
            "$L__BB0_2:\n",
            "\tret;\n",
            "\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_ptx.c\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define CHECK_CUDA(call) \\\n",
        "    do { \\\n",
        "        CUresult err = call; \\\n",
        "        if (err != CUDA_SUCCESS) { \\\n",
        "            const char *errStr; \\\n",
        "            cuGetErrorString(err, &errStr); \\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, errStr); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "int main() {\n",
        "    // Initialize CUDA\n",
        "    CHECK_CUDA(cuInit(0));\n",
        "\n",
        "    CUdevice device;\n",
        "    CUcontext context;\n",
        "    CHECK_CUDA(cuDeviceGet(&device, 0));\n",
        "    CHECK_CUDA(cuCtxCreate(&context, 0, device));\n",
        "\n",
        "    // Load PTX module from file\n",
        "    CUmodule module;\n",
        "    CHECK_CUDA(cuModuleLoad(&module, \"vector_add.ptx\"));\n",
        "\n",
        "    // Get function\n",
        "    CUfunction kernel;\n",
        "    CHECK_CUDA(cuModuleGetFunction(&kernel, module, \"_Z9vectorAddPKfS0_Pfi\"));\n",
        "\n",
        "    // Setup data\n",
        "    int n = 1000000;\n",
        "    size_t size = n * sizeof(float);\n",
        "\n",
        "    float *h_a = (float*)malloc(size);\n",
        "    float *h_b = (float*)malloc(size);\n",
        "    float *h_c = (float*)malloc(size);\n",
        "\n",
        "    // Initialize arrays\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = (float)i;\n",
        "        h_b[i] = (float)i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    CUdeviceptr d_a, d_b, d_c;\n",
        "    CHECK_CUDA(cuMemAlloc(&d_a, size));\n",
        "    CHECK_CUDA(cuMemAlloc(&d_b, size));\n",
        "    CHECK_CUDA(cuMemAlloc(&d_c, size));\n",
        "\n",
        "    // Copy to device\n",
        "    CHECK_CUDA(cuMemcpyHtoD(d_a, h_a, size));\n",
        "    CHECK_CUDA(cuMemcpyHtoD(d_b, h_b, size));\n",
        "\n",
        "    // Launch kernel\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (n + blockSize - 1) / blockSize;\n",
        "\n",
        "    void *args[] = { &d_a, &d_b, &d_c, &n };\n",
        "\n",
        "    CHECK_CUDA(cuLaunchKernel(\n",
        "        kernel,\n",
        "        gridSize, 1, 1,    // grid\n",
        "        blockSize, 1, 1,   // block\n",
        "        0, NULL,           // shared mem, stream\n",
        "        args, NULL\n",
        "    ));\n",
        "\n",
        "    // Copy result back\n",
        "    CHECK_CUDA(cuMemcpyDtoH(h_c, d_c, size));\n",
        "\n",
        "    // Verify\n",
        "    printf(\"First 10 results:\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%.2f + %.2f = %.2f\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    cuMemFree(d_a);\n",
        "    cuMemFree(d_b);\n",
        "    cuMemFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    cuCtxDestroy(context);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeGF2B7rWqAN",
        "outputId": "30e49874-bac8-4a4f-b83b-29e09b73b1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_ptx.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o run_ptx run_ptx.c -lcuda\n",
        "!./run_ptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTIWzKBJW8CH",
        "outputId": "a741b910-6872-4beb-8046-b1c87c182042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0.00 + 0.00 = 0.00\n",
            "1.00 + 2.00 = 3.00\n",
            "2.00 + 4.00 = 6.00\n",
            "3.00 + 6.00 = 9.00\n",
            "4.00 + 8.00 = 12.00\n",
            "5.00 + 10.00 = 15.00\n",
            "6.00 + 12.00 = 18.00\n",
            "7.00 + 14.00 = 21.00\n",
            "8.00 + 16.00 = 24.00\n",
            "9.00 + 18.00 = 27.00\n"
          ]
        }
      ]
    }
  ]
}