{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# proof cooperative scheduling on memory fetching is each memory instruction act like an await or yield allow the scheduler to switch the warps\n",
        "# flood the sm with max blocks with pure compute ie an infinite loop so it can switch to another warp or taken in another warp\n",
        "# run info cuda sms to see that all 40 sm are working\n",
        "# run info cuda warps to see all 32 warps per sm\n",
        "# unable to launch with more than 1024 threads in a block or more than 32 warps per sm\n",
        "# check max block and grid size"
      ],
      "metadata": {
        "id": "mPgP45ezRkaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tymRGjOvYEf",
        "outputId": "aa2ea92c-a762-45f7-c8a1-eb2cf6326e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile test.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <unistd.h>\n",
        "\n",
        "__global__ void infinite_kernel() { while (true) {} }\n",
        "\n",
        "__global__ void test_kernel() { printf(\"Hello from test kernel! If you see this, some SMs were still free.\\n\"); }\n",
        "\n",
        "\n",
        "int main() {\n",
        "    printf(\"Starting test on T4 GPU...\\n\");\n",
        "\n",
        "    // T4 has 40 SMs, so launching > 40 blocks ensures full SM occupancy\n",
        "    // Each block runs an infinite loop, preventing other kernels from running\n",
        "    // using dim3(x, y, z) type to define the thread in each dimension more explicitly\n",
        "    // 1024 and 2147483647, 65535, 65535 max limit !!!!!!\n",
        "\n",
        "    infinite_kernel<<<dim3(40, 1, 1), dim3(1024, 1, 1)>>>();\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Error launching infinite kernel: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    sleep(1);\n",
        "\n",
        "    printf(\"Launching test_kernel...\\n\");\n",
        "    test_kernel<<<dim3(1, 1, 1), dim3(1, 1, 1)>>>();\n",
        "\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        printf(\"Error launching test kernel: %s\\n\", cudaGetErrorString(err));\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    printf(\"Synchronizing device (expected to hang here)...\\n\");\n",
        "    err = cudaDeviceSynchronize();  // <--- FREEZES HERE\n",
        "\n",
        "    if (err != cudaSuccess) { printf(\"Sync error: %s\\n\", cudaGetErrorString(err)); }\n",
        "\n",
        "    printf(\"I Should not be seen!!!\\n\");\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o test test.cu\n",
        "!./test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOW3Z7-wJAV",
        "outputId": "3a7e93ca-d7bb-4a0f-8bc8-8cfbacf0eddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting test on T4 GPU...\n",
            "Error launching infinite kernel: invalid configuration argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nvidia-smi\n",
        "# nvidia-smi dmon -s u -c 10"
      ],
      "metadata": {
        "id": "VX6J36k2ze5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}