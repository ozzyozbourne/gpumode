{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO_eQvEsfFUw",
        "outputId": "9cb44f1e-63f5-47a6-c54c-b2a7e641957b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.ptx\n"
          ]
        }
      ],
      "source": [
        "%%writefile vector_add.ptx\n",
        "//\n",
        "// Generated by NVIDIA NVVM Compiler\n",
        "//\n",
        "// Compiler Build ID: CL-34385749\n",
        "// Cuda compilation tools, release 12.5, V12.5.82\n",
        "// Based on NVVM 7.0.1\n",
        "//\n",
        "\n",
        ".version 8.4\n",
        ".target sm_52\n",
        ".address_size 64\n",
        "\n",
        "\t// .globl\t_Z9vectorAddPKfS0_Pfi\n",
        "\n",
        ".visible .entry _Z9vectorAddPKfS0_Pfi(\n",
        "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_0,\n",
        "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_1,\n",
        "\t.param .u64 _Z9vectorAddPKfS0_Pfi_param_2,\n",
        "\t.param .u32 _Z9vectorAddPKfS0_Pfi_param_3\n",
        ")\n",
        "{\n",
        "\t.reg .pred \t%p<2>;\n",
        "\t.reg .f32 \t%f<4>;\n",
        "\t.reg .b32 \t%r<6>;\n",
        "\t.reg .b64 \t%rd<11>;\n",
        "\n",
        "\n",
        "\tld.param.u64 \t%rd1, [_Z9vectorAddPKfS0_Pfi_param_0];\n",
        "\tld.param.u64 \t%rd2, [_Z9vectorAddPKfS0_Pfi_param_1];\n",
        "\tld.param.u64 \t%rd3, [_Z9vectorAddPKfS0_Pfi_param_2];\n",
        "\tld.param.u32 \t%r2, [_Z9vectorAddPKfS0_Pfi_param_3];\n",
        "\tmov.u32 \t%r3, %ctaid.x;\n",
        "\tmov.u32 \t%r4, %ntid.x;\n",
        "\tmov.u32 \t%r5, %tid.x;\n",
        "\tmad.lo.s32 \t%r1, %r3, %r4, %r5;\n",
        "\tsetp.ge.s32 \t%p1, %r1, %r2;\n",
        "\t@%p1 bra \t$L__BB0_2;\n",
        "\n",
        "\tcvta.to.global.u64 \t%rd4, %rd1;\n",
        "\tmul.wide.s32 \t%rd5, %r1, 4;\n",
        "\tadd.s64 \t%rd6, %rd4, %rd5;\n",
        "\tcvta.to.global.u64 \t%rd7, %rd2;\n",
        "\tadd.s64 \t%rd8, %rd7, %rd5;\n",
        "\tld.global.f32 \t%f1, [%rd8];\n",
        "\tld.global.f32 \t%f2, [%rd6];\n",
        "\tadd.f32 \t%f3, %f2, %f1;\n",
        "\tcvta.to.global.u64 \t%rd9, %rd3;\n",
        "\tadd.s64 \t%rd10, %rd9, %rd5;\n",
        "\tst.global.f32 \t[%rd10], %f3;\n",
        "\n",
        "$L__BB0_2:\n",
        "\tret;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_ptx.c\n",
        "#include <cuda.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define CHECK_CUDA(call) \\\n",
        "    do { \\\n",
        "        CUresult err = call; \\\n",
        "        if (err != CUDA_SUCCESS) { \\\n",
        "            const char *errStr; \\\n",
        "            cuGetErrorString(err, &errStr); \\\n",
        "            fprintf(stderr, \"CUDA error at %s:%d: %s\\n\", __FILE__, __LINE__, errStr); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while(0)\n",
        "\n",
        "int main() {\n",
        "    // Initialize CUDA\n",
        "    CHECK_CUDA(cuInit(0));\n",
        "\n",
        "    CUdevice device;\n",
        "    CUcontext context;\n",
        "    CHECK_CUDA(cuDeviceGet(&device, 0));\n",
        "    CHECK_CUDA(cuCtxCreate(&context, 0, device));\n",
        "\n",
        "    // Load PTX module from file\n",
        "    CUmodule module;\n",
        "    CHECK_CUDA(cuModuleLoad(&module, \"vector_add.ptx\"));\n",
        "\n",
        "    // Get function\n",
        "    CUfunction kernel;\n",
        "    CHECK_CUDA(cuModuleGetFunction(&kernel, module, \"_Z9vectorAddPKfS0_Pfi\"));\n",
        "\n",
        "    // Setup data\n",
        "    int n = 1000000;\n",
        "    size_t size = n * sizeof(float);\n",
        "\n",
        "    float *h_a = (float*)malloc(size);\n",
        "    float *h_b = (float*)malloc(size);\n",
        "    float *h_c = (float*)malloc(size);\n",
        "\n",
        "    // Initialize arrays\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = (float)i;\n",
        "        h_b[i] = (float)i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    CUdeviceptr d_a, d_b, d_c;\n",
        "    CHECK_CUDA(cuMemAlloc(&d_a, size));\n",
        "    CHECK_CUDA(cuMemAlloc(&d_b, size));\n",
        "    CHECK_CUDA(cuMemAlloc(&d_c, size));\n",
        "\n",
        "    // Copy to device\n",
        "    CHECK_CUDA(cuMemcpyHtoD(d_a, h_a, size));\n",
        "    CHECK_CUDA(cuMemcpyHtoD(d_b, h_b, size));\n",
        "\n",
        "    // Launch kernel\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (n + blockSize - 1) / blockSize;\n",
        "\n",
        "    void *args[] = { &d_a, &d_b, &d_c, &n };\n",
        "\n",
        "    CHECK_CUDA(cuLaunchKernel(\n",
        "        kernel,\n",
        "        gridSize, 1, 1,    // grid\n",
        "        blockSize, 1, 1,   // block\n",
        "        0, NULL,           // shared mem, stream\n",
        "        args, NULL\n",
        "    ));\n",
        "\n",
        "    // Copy result back\n",
        "    CHECK_CUDA(cuMemcpyDtoH(h_c, d_c, size));\n",
        "\n",
        "    // Verify\n",
        "    printf(\"First 10 results:\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%.2f + %.2f = %.2f\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    cuMemFree(d_a);\n",
        "    cuMemFree(d_b);\n",
        "    cuMemFree(d_c);\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "    cuCtxDestroy(context);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DF-Z-1rfZAA",
        "outputId": "a0ed78cd-460b-40c9-b23a-8549736ab243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_ptx.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o run_ptx run_ptx.c -lcuda\n",
        "!./run_ptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNztPeCsfeIW",
        "outputId": "5dcc6332-f86c-4d2b-aba7-897777c62da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 results:\n",
            "0.00 + 0.00 = 0.00\n",
            "1.00 + 2.00 = 3.00\n",
            "2.00 + 4.00 = 6.00\n",
            "3.00 + 6.00 = 9.00\n",
            "4.00 + 8.00 = 12.00\n",
            "5.00 + 10.00 = 15.00\n",
            "6.00 + 12.00 = 18.00\n",
            "7.00 + 14.00 = 21.00\n",
            "8.00 + 16.00 = 24.00\n",
            "9.00 + 18.00 = 27.00\n"
          ]
        }
      ]
    }
  ]
}